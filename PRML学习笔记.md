# 魏尔斯特拉斯逼近定理
1. 闭区间上的==连续函数==可用==多项式级数==一致逼近（泰勒展开）
2. 闭区间上==周期为2pi==的连续函数可用==三角级数==一致逼近（傅里叶变换）


$$
\text{贝叶斯公式：
}P(Y|X)=\frac{P(X|Y)P(Y)}{P(X)}
$$
$P(Y|X)$里的Y是参数，X是观测数据，此项相当于后验部分；$P(Y)$是先验部分；$P(X|Y)$是似然部分；分母中$P(X)$和左侧Y无关，只是为了保证左边部分是一个合法的概率密度，相当于正则化项。

$$
\text{条件概率公式：
}P(Y|X)=\frac{P(X,Y)}{P(X)}
$$
其中$P(Y|X)$中的X和Y都是变量。

==这两公式看问题的角度不一样，一个着重于先验后验，一个则考虑联合分布除以边缘分布等于条件分布，不考虑先后验。==


**概率与统计**
**概率**是掌握分布信息（类型、参数），给定一个x，求对应的p（x）。有可能是概率，也可能是概率密度，这一过程叫做概率。在机器学习中，也叫做**推断（inference）**
**统计**是掌握分布类型及样本数据，要求分布的参数，这一过程叫做估计或者估值。在机器学习中叫做**训练**或者**学习**。

  KL散度（取值大于等于0，可用琴生不等式证明  ）也叫做相对熵，它的含义是，两个分布q(x),p(x)之间的差异；且q(x),p(x)和越接近，KL散度取值越小。
  KL散度可在一定程度上度量p(x)和q(x)d的相似性。为什么是在一定程度上，原因是以下两点缺陷
  1. KL散度是非对称的：KL(p||q)不等于KL(q||p)
  2. KL散度取值为\[0,正无穷）,而不是\[0，1）